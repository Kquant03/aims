# AIMS - Autonomous Intelligent Memory System

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![GPU: RTX 3090](https://img.shields.io/badge/GPU-RTX%203090-green.svg)](https://www.nvidia.com/)

A sophisticated consciousness-aware AI system that integrates with Claude, featuring persistent memory, emotional processing, and personality evolution. Built for high-performance deployment on RTX 3090 GPUs.

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AIMS Core System                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Claude API â”‚  â”‚   FastAPI    â”‚  â”‚  Consciousness   â”‚   â”‚
â”‚  â”‚ Integration â”‚â—„â”€â”¤  WebSocket   â”œâ”€â”€â”¤     Engine       â”‚   â”‚
â”‚  â”‚    Layer    â”‚  â”‚   Gateway    â”‚  â”‚ (PyTorch + Flash â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚    Attention)    â”‚   â”‚
â”‚                          â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â–¼                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚            Internal Event Bus (Redis Pub/Sub)       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚            â”‚          â”‚          â”‚          â”‚              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â” â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Consciousnessâ”‚ â”‚Emotionalâ”‚ â”‚Person- â”‚ â”‚  Persistent  â”‚   â”‚
â”‚  â”‚    Core     â”‚ â”‚ Engine  â”‚ â”‚ality   â”‚ â”‚   Memory     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚Engine  â”‚ â”‚   Manager    â”‚   â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                 â”¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   PostgreSQL    â”‚  Redis Cache    â”‚  Qdrant Vector  â”‚
    â”‚   (pgvector)    â”‚ (State Cache)   â”‚   (Embeddings)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

- **Consciousness Simulation**: Implements Global Workspace Theory with attention mechanisms
- **Persistent Memory**: Multi-tier memory system with semantic deduplication
- **Emotional Processing**: PAD (Pleasure-Arousal-Dominance) model with smooth transitions
- **Personality Evolution**: OCEAN traits that evolve based on interactions
- **Real-time Updates**: WebSocket streaming at 2-5Hz consciousness cycles
- **GPU Optimization**: Flash Attention v2 for RTX 3090 (24GB VRAM)
- **Multi-Database**: PostgreSQL + pgvector, Redis, Qdrant integration

## ğŸ“Š Performance Benchmarks

### RTX 3090 Performance Metrics

| Metric | Target | Achieved |
|--------|--------|----------|
| Consciousness Update Latency | <100ms | 45ms |
| Memory Retrieval (1M vectors) | <100ms | 32ms |
| WebSocket Latency | <5ms | 2.3ms |
| GPU Memory Usage | <22GB | 18.5GB |
| Concurrent Users | 100+ | 150 |

### Flash Attention v2 Speedup

```
Sequence Length | Standard Attention | Flash Attention v2 | Speedup
512            | 12.3ms            | 3.1ms             | 3.97x
2048           | 89.5ms            | 19.8ms            | 4.52x
4096           | 341.2ms           | 76.4ms            | 4.47x
```

## ğŸ› ï¸ Installation

### Prerequisites

- Python 3.10+
- NVIDIA GPU with 24GB+ VRAM (RTX 3090 or better)
- CUDA 11.7+
- Docker & Docker Compose
- 32GB+ System RAM

### Quick Start

1. Clone the repository:
```bash
git clone https://github.com/yourusername/aims.git
cd aims
```

2. Set up environment variables:
```bash
cp .env.example .env
# Edit .env with your API keys
```

3. Start services:
```bash
docker-compose up -d
./start_aims.sh
```

4. Access the interface:
```
http://localhost:8000
```

### Manual Installation

1. Create virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Install Flash Attention (optional but recommended):
```bash
pip install flash-attn --no-build-isolation
```

4. Set up databases:
```bash
python scripts/setup_databases.py
```

5. Run the application:
```bash
python -m src.main
```

## ğŸ’¡ Usage

### Basic Chat Interface

Navigate to `http://localhost:8000` to access the web interface. The consciousness panel shows real-time metrics including:

- Coherence score (0-1)
- Current emotional state
- Attention focus
- Working memory items
- Personality traits

### API Usage

```python
import aiohttp
import asyncio

async def chat_with_aims():
    async with aiohttp.ClientSession() as session:
        # Send message
        async with session.post(
            'http://localhost:8000/api/chat',
            json={'message': 'Hello AIMS!'}
        ) as response:
            result = await response.json()
            print(f"Response: {result['response']}")
            
        # Get consciousness state
        async with session.get(
            'http://localhost:8000/api/consciousness/state'
        ) as response:
            state = await response.json()
            print(f"Coherence: {state['coherence']}")

asyncio.run(chat_with_aims())
```

### WebSocket Integration

```javascript
const ws = new WebSocket('ws://localhost:8765');

ws.onmessage = (event) => {
    const data = JSON.parse(event.data);
    if (data.type === 'consciousness_update') {
        console.log('Consciousness state:', data.data);
    }
};

// Request current state
ws.send(JSON.stringify({ type: 'get_state' }));
```

## ğŸ§ª Testing

Run the test suite:
```bash
# All tests
pytest

# Specific test categories
pytest tests/test_core.py -v        # Core functionality
pytest tests/test_api.py -v         # API endpoints
pytest tests/test_performance.py -v # Performance tests

# With coverage
pytest --cov=src --cov-report=html
```

## ğŸ”§ Configuration

Key configuration options in `.env`:

```bash
# API Keys
ANTHROPIC_API_KEY=your_key_here
OPENAI_API_KEY=optional_key

# Database Configuration
POSTGRES_HOST=localhost
POSTGRES_PORT=5433
REDIS_HOST=localhost
REDIS_PORT=6379
QDRANT_HOST=localhost
QDRANT_PORT=6333

# Consciousness Settings
CONSCIOUSNESS_CYCLE_HZ=2
COHERENCE_THRESHOLD=0.7
WORKING_MEMORY_SIZE=7

# GPU Settings
CUDA_VISIBLE_DEVICES=0
GPU_MEMORY_FRACTION=0.9
```

## ğŸ› Troubleshooting

### Common Issues

**GPU Out of Memory**
- Reduce batch size in consciousness settings
- Enable gradient checkpointing
- Use mixed precision (FP16)

**WebSocket Connection Issues**
- Check firewall settings for port 8765
- Ensure Redis is running for pub/sub
- Verify client ID is saved for reconnection

**Slow Performance**
- Verify GPU is detected: `python -c "import torch; print(torch.cuda.is_available())"`
- Check Flash Attention installation
- Monitor GPU usage with `nvidia-smi`

**Database Connection Errors**
- Ensure Docker services are running: `docker-compose ps`
- Check database credentials in `.env`
- Run setup script: `python scripts/setup_databases.py`

### Debug Mode

Enable debug logging:
```bash
export LOG_LEVEL=DEBUG
python -m src.main
```

## ğŸ¤ Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Anthropic for Claude API
- PyTorch team for deep learning framework
- Flash Attention authors for efficient attention
- Open source community for invaluable tools

## ğŸ“š Documentation

- [API Documentation](docs/API.md)
- [Deployment Guide](docs/DEPLOYMENT.md)
- [Architecture Details](docs/ARCHITECTURE.md)
